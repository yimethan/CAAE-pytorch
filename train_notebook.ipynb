{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7d1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchsummary\n",
    "\n",
    "from config import Config\n",
    "from caae import *\n",
    "from load_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4d6a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1c1d5664a60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72402800",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671edbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa51da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(real_samples, fake_samples, discriminator):\n",
    "    # Generate random epsilon for interpolation\n",
    "    epsilon = torch.rand(real_samples.size(0), 1)\n",
    "    epsilon = epsilon.expand_as(real_samples).to(device)\n",
    "\n",
    "    # Interpolate between real and fake samples\n",
    "    interpolated = epsilon * real_samples + (1 - epsilon) * fake_samples\n",
    "    interpolated.requires_grad_(True).to(device)\n",
    "\n",
    "    # Calculate discriminator scores on the interpolated samples\n",
    "    d_interpolated = discriminator(interpolated).to(device)\n",
    "\n",
    "    # Compute gradients of the scores with respect to the interpolated samples\n",
    "    gradients = torch.autograd.grad(outputs=d_interpolated, inputs=interpolated,\n",
    "                                    grad_outputs=torch.ones(d_interpolated.size()).to(device),\n",
    "                                    create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    # Compute the gradient penalty\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    g_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()  # Penalty term\n",
    "\n",
    "    return g_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123f2707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, epoch):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    fnr = fn / (tp + fn)\n",
    "    err = (fn + fp) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = 1 - fnr\n",
    "    f1score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    print('---Test results-------')\n",
    "\n",
    "    print('TP:', tp, 'FN:', fn)\n",
    "    print('FP:', fp, 'TN:', tn)\n",
    "    print('False negative rate: ', fnr)\n",
    "    print('Error rate: ', err)\n",
    "    print('Precision: ', precision)\n",
    "    print('Recall: ', recall)\n",
    "    print('F1 score: ', f1score)\n",
    "\n",
    "    writer.add_scalar('test/False_negative_rate', fnr, epoch)\n",
    "    writer.add_scalar('test/Error_rate', err, epoch)\n",
    "    writer.add_scalar('test/Precision', precision, epoch)\n",
    "    writer.add_scalar('test/Recall', recall, epoch)\n",
    "    writer.add_scalar('test/F1_score', f1score, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6116ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)\n",
    "discriminator_g = Disgauss().to(device)\n",
    "discriminator_c = Discateg().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac385a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                             lr=Config.reconstruction_lr, betas=(Config.beta1, Config.beta2))\n",
    "discriminator_g_optimizer = Adam(discriminator_g.parameters(), lr=Config.regularization_lr,\n",
    "                                 betas=(Config.beta1, Config.beta2))\n",
    "discriminator_c_optimizer = Adam(discriminator_c.parameters(), lr=Config.regularization_lr,\n",
    "                                 betas=(Config.beta1, Config.beta2))\n",
    "generator_optimizer = Adam(encoder.parameters(), lr=Config.regularization_lr, betas=(Config.beta1, Config.beta2))\n",
    "supervised_encoder_optimizer = Adam(encoder.parameters(), lr=Config.supervised_lr,\n",
    "                                    betas=(Config.beta1_sup, Config.beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30f622c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_scheduler = lr_scheduler.StepLR(autoencoder_optimizer, step_size=50, gamma=Config.gamma)\n",
    "supervised_scheduler = lr_scheduler.StepLR(supervised_encoder_optimizer, step_size=50, gamma=Config.gamma)\n",
    "disc_g_scheduler = lr_scheduler.StepLR(discriminator_g_optimizer, step_size=50, gamma=Config.gamma)\n",
    "disc_c_scheduler = lr_scheduler.StepLR(discriminator_c_optimizer, step_size=50, gamma=Config.gamma)\n",
    "generator_scheduler = lr_scheduler.StepLR(generator_optimizer, step_size=50, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2222beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GetDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d0e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = int(len(dataset) * 0.7)\n",
    "# train_labeled_size = int(train_len * Config.labeled_percentage)\n",
    "# train_unlabeled_size = train_len - train_labeled_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9332ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_len = len(dataset) - train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36fd6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataset, test_size=0.3, random_state=42, shuffle=False)\n",
    "train_labeled_data, train_unlabeled_data = train_test_split(train_data, test_size=0.9, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d261f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_loader = DataLoader(train_labeled_data, batch_size=Config.batch_size)\n",
    "train_unlabeled_loader = DataLoader(train_unlabeled_data, batch_size=Config.batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=Config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b973d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             320\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]           9,248\n",
      "              ReLU-5           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
      "            Conv2d-7             [-1, 64, 8, 8]          18,496\n",
      "              ReLU-8             [-1, 64, 8, 8]               0\n",
      "         MaxPool2d-9             [-1, 64, 4, 4]               0\n",
      "           Conv2d-10             [-1, 64, 4, 4]          36,928\n",
      "             ReLU-11             [-1, 64, 4, 4]               0\n",
      "        MaxPool2d-12             [-1, 64, 2, 2]               0\n",
      "          Dropout-13             [-1, 64, 2, 2]               0\n",
      "================================================================\n",
      "Total params: 64,992\n",
      "Trainable params: 64,992\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.79\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 1.04\n",
      "----------------------------------------------------------------\n",
      "torch.Size([2, 12])\n",
      "torch.Size([2, 256])\n",
      "torch.Size([2, 256])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv_transpose2d, but got input of size: [2, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torchsummary\u001b[38;5;241m.\u001b[39msummary(encoder, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m29\u001b[39m, \u001b[38;5;241m29\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorchsummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m torchsummary\u001b[38;5;241m.\u001b[39msummary(discriminator_g, (\u001b[38;5;241m10\u001b[39m,))\n\u001b[0;32m      4\u001b[0m torchsummary\u001b[38;5;241m.\u001b[39msummary(discriminator_c, (\u001b[38;5;241m2\u001b[39m,))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\CAAE-pytorch\\caae.py:110\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# x = x.view(-1, 64, 2, 2)\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 110\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeconv0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# batch * 64 * 2 * 2\u001b[39;00m\n\u001b[0;32m    111\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu0(x)\n\u001b[0;32m    112\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample(x)  \u001b[38;5;66;03m# batch * 64 * 4 * 4\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1543\u001b[0m     ):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:956\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[1;34m(self, input, output_size)\u001b[0m\n\u001b[0;32m    951\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    952\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    954\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv_transpose2d, but got input of size: [2, 256]"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(encoder, (1, 29, 29))\n",
    "torchsummary.summary(decoder, (12,))\n",
    "torchsummary.summary(discriminator_g, (10,))\n",
    "torchsummary.summary(discriminator_c, (2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(Config.epochs):\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        discriminator_g.train()\n",
    "        discriminator_c.train()\n",
    "\n",
    "        print(\"------------------ Epoch {}/{} ------------------\".format(epoch, Config.epochs))\n",
    "\n",
    "        for batch_idx, labeled in enumerate(train_labeled_loader):\n",
    "            unlabeled = next(iter(train_unlabeled_loader))\n",
    "\n",
    "            autoencoder_optimizer.zero_grad()\n",
    "            discriminator_g_optimizer.zero_grad()\n",
    "            discriminator_c_optimizer.zero_grad()\n",
    "            generator_optimizer.zero_grad()\n",
    "            supervised_encoder_optimizer.zero_grad()\n",
    "\n",
    "            x_labeled, y_labeled = labeled['input'].to(device), labeled['label'].to(device)\n",
    "            x_unlabeled, y_unlabeled = unlabeled['input'].to(device), unlabeled['label'].to(device)\n",
    "\n",
    "            z_real_dist = torch.randn(Config.batch_size, Config.z_dim) * 5.\n",
    "            real_cat_dist = torch.randint(low=0, high=2, size=(Config.batch_size,))\n",
    "            real_cat_dist = torch.eye(Config.n_labels)[real_cat_dist]  # one-hot encoded\n",
    "\n",
    "            z_real_dist = z_real_dist.to(device)\n",
    "            real_cat_dist = real_cat_dist.to(device)\n",
    "\n",
    "            encoder_output_label, encoder_output_latent = encoder(x_unlabeled)\n",
    "            decoder_input = torch.cat((encoder_output_label, encoder_output_latent), dim=1)\n",
    "            decoder_output = decoder(decoder_input).to(device)\n",
    "\n",
    "            autoencoder_loss = F.mse_loss(decoder_output, x_unlabeled)\n",
    "\n",
    "            autoencoder_loss.backward()\n",
    "            autoencoder_optimizer.step()\n",
    "\n",
    "            # wgan-gp\n",
    "            for _ in range(5):\n",
    "                encoder_output_label, encoder_output_latent = encoder(x_unlabeled)\n",
    "\n",
    "                d_g_real = discriminator_g(z_real_dist)\n",
    "                d_g_fake = discriminator_g(encoder_output_latent)\n",
    "\n",
    "                real_penalty = gradient_penalty(z_real_dist, encoder_output_latent, discriminator_g).to(device)\n",
    "                dc_g_loss = -torch.mean(d_g_real) + torch.mean(d_g_fake) + 10.0 * real_penalty\n",
    "\n",
    "                discriminator_g_optimizer.zero_grad()\n",
    "\n",
    "                dc_g_loss.backward()\n",
    "                discriminator_g_optimizer.step()\n",
    "\n",
    "                encoder_output_label, encoder_output_latent = encoder(x_unlabeled)\n",
    "\n",
    "                d_c_real = discriminator_c(real_cat_dist)\n",
    "                d_c_fake = discriminator_c(encoder_output_label)\n",
    "\n",
    "                fake_penalty = gradient_penalty(real_cat_dist, encoder_output_label, discriminator_c).to(device)\n",
    "                dc_c_loss = -torch.mean(d_c_real) + torch.mean(d_c_fake) + 10.0 * fake_penalty\n",
    "\n",
    "                discriminator_c_optimizer.zero_grad()\n",
    "\n",
    "                dc_c_loss.backward()\n",
    "                discriminator_c_optimizer.step()\n",
    "\n",
    "            # generator\n",
    "            # d_g_fake = d_g_fake.requires_grad_(True)\n",
    "            # d_c_fake = d_c_fake.requires_grad_(True)\n",
    "            _encoder_output_label, _encoder_output_latent = encoder(x_unlabeled)\n",
    "            d_g_fake = discriminator_g(_encoder_output_latent).to(device)\n",
    "            d_c_fake = discriminator_c(_encoder_output_label).to(device)\n",
    "\n",
    "            generator_g_loss = -torch.mean(torch.log(d_g_fake + 1e-8))\n",
    "            generator_c_loss = -torch.mean(torch.log(d_c_fake + 1e-8))\n",
    "\n",
    "            # generator_loss = -torch.mean(d_g_fake) - torch.mean(d_c_fake)\n",
    "            generator_loss = generator_g_loss + generator_c_loss\n",
    "\n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "\n",
    "            # Semi-Supervised Classification Phase\n",
    "            encoder_output_label_, encoder_output_latent_ = encoder(x_labeled, supervised=True)\n",
    "\n",
    "            # Classification accuracy of encoder\n",
    "            output_label = torch.argmax(encoder_output_label_, dim=1)\n",
    "            correct_pred = output_label.eq(y_labeled)\n",
    "            accuracy = torch.mean(correct_pred.float())\n",
    "\n",
    "            supervised_encoder_loss = F.cross_entropy(encoder_output_label_, y_labeled)\n",
    "\n",
    "            supervised_encoder_loss.backward()\n",
    "            supervised_encoder_optimizer.step()\n",
    "\n",
    "        writer.add_scalar('train/loss/autoencoder_loss', autoencoder_loss, epoch)\n",
    "        writer.add_scalar('train/loss/dc_g_loss', dc_g_loss, epoch)\n",
    "        writer.add_scalar('train/loss/dc_c_loss', dc_c_loss, epoch)\n",
    "        writer.add_scalar('train/loss/generator_loss', generator_loss, epoch)\n",
    "        writer.add_scalar('train/loss/supervised_encoder_loss', supervised_encoder_loss, epoch)\n",
    "\n",
    "        writer.add_scalar('train/encoder_accuracy', accuracy, epoch)\n",
    "\n",
    "        writer.add_image('train/decoder_output', decoder_output[0], epoch)\n",
    "\n",
    "        reconstruction_scheduler.step()\n",
    "        supervised_scheduler.step()\n",
    "        disc_g_scheduler.step()\n",
    "        disc_c_scheduler.step()\n",
    "        generator_scheduler.step()\n",
    "\n",
    "        test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd0f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # total_prob = []\n",
    "    # total_latent = []\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    discriminator_g.eval()\n",
    "    discriminator_c.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, inputs in enumerate(test_loader):\n",
    "\n",
    "            x = inputs['input'].to(device)\n",
    "            y = inputs['label'].to(device)\n",
    "\n",
    "            batch_pred, batch_latent = encoder(x)\n",
    "            # total_latent.append(batch_latent.cpu().numpy())\n",
    "\n",
    "            # TODO: every sample in a batch has same values\n",
    "\n",
    "            # print(batch_pred)\n",
    "\n",
    "            batch_label = y.cpu().numpy()\n",
    "            batch_pred = batch_pred.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "            print('batch_pred', batch_pred)\n",
    "\n",
    "            y_pred.extend(batch_pred.tolist())\n",
    "            y_true.extend(batch_label.tolist())\n",
    "            # total_prob.extend(prob.tolist())\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        # total_prob = np.array(total_prob)\n",
    "        # total_latent = np.concatenate(total_latent, axis=0)\n",
    "\n",
    "        evaluate(y_true, y_pred, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5b2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e07dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d2980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b94385",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('imageData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0bef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a870ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=29x29 at 0x1E64A252170>\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff800b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f2d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('imageData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b040392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(1 in img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8ca52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
